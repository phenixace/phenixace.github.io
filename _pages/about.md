---
permalink: /
title: "Introduction"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am currently a visiting scholar at The BlueWhale Lab, National University of Singapore (NUS), and a Ph.D. candidate in the Department of Computing (COMP), The Hong Kong Polytechnic University (funded by **HKPFS**). Prior to joining PolyU, I received my Master's degree in Information Technology (with Distinction) from the University of Melbourne, under the supervision of Dr. Lea Frermann. I obtained my Bachelor's degree in Information Security from Shanghai Jiao Tong University in 2021.

My research interests lie in **Natural Language Processing**, **Drug Discovery**, and **Large Language Models**. I have published several papers in top-tier conferences and journals, including CVPR, ACL, IJCAI, and IEEE TKDE. I served as a Program Committee member of AAAI 2024 & 2025, and as a reviewer for ICML, NeurIPS, and ICLR.

I am always open to new opportunities and collaborations. If you are interested in my research, please feel free to contact me.

Research Interests
======
* Natural Language Processing
* Drug Discovery
* Large Language Models

News
======
* **[2026.02]** Our paper "IAG: Input-Aware Backdoor Attack on VLM-Based Visual Grounding" is accepted by **CVPR 2026**. Congratulations to Junxian Li! ðŸŽ‰ [[Paper]](https://arxiv.org/abs/2508.09456)
* **[2026.01]** Our paper "CMPhysBench: A Benchmark for Evaluating Large Language Models in Condensed Matter Physics" is accepted by **ICLR 2026**. Congratulations to Weida Wang! ðŸŽ‰ [[Paper]](https://arxiv.org/abs/2508.18124)
* **[2025.08]** Our paper "Mol-R1: Towards Explicit Long-CoT Reasoning in Molecule Discovery" is available on arXiv. [[Paper]](https://arxiv.org/abs/2508.08401)
* **[2025.06]** We are organizing a workshop "LLM Reasoning on Medicine: Challenges, Opportunities, and Future" at **INLG 2025**. [[Workshop Link]](https://softconf.com/p/llmrm2025/)
* **[2025.03]** Our paper "Large Language Models are In-Context Molecule Learners" is accepted by **IEEE TKDE**! ðŸŽ‰ [[Paper]](https://arxiv.org/abs/2403.04197) [[Model]](https://huggingface.co/phenixace/) [[Code]](https://github.com/phenixace/ICMA)
* **[2025.02]** Our paper "Critic-V: VLM Critics Help Catch VLM Errors in Multimodal Reasoning" is accepted by **CVPR 2025**. Congratulations to Di Zhang! ðŸŽ‰
* **[2024.12]** Our paper "TOMG-Bench: Evaluating LLMs on Text-based Open Molecule Generation" is released on arXiv. [[Paper]](https://arxiv.org/abs/2412.14642) [[Homepage]](https://phenixace.github.io/tomgbench/) [[Code]](https://github.com/phenixace/S2-TOMG-Bench) [[Data]](https://huggingface.co/datasets/phenixace/S2-TOMG-Bench)
* **[2024.11]** Our paper "MolReFlect: Towards In-Context Fine-grained Alignments between Molecules and Texts" is released on arXiv. [[Paper]](https://arxiv.org/abs/2411.14721)
* **[2024.06]** Our paper "Empowering Molecule Discovery for Molecule-Caption Translation with Large Language Models: A ChatGPT Perspective" is accepted by **IEEE TKDE**. [[Paper]](https://arxiv.org/abs/2306.06615)
* **[2024.03]** Our paper "Recommender Systems in the Era of Large Language Models (LLMs)" is accepted by **IEEE TKDE**! [[Paper]](https://arxiv.org/abs/2307.02046)

Publications
======
<div style="height: 400px; overflow-y: scroll;">

**2026**

* Weida Wang, Dongchen Huang, **Jiatong Li**, Tengchao Yang, Ziyang Zheng, Di Zhang, Dong Han et al. CMPhysBench: A Benchmark for Evaluating Large Language Models in Condensed Matter Physics. **ICLR 2026**.
* Junxian Li, Beining Xu, Simin Chen, **Jiatong Li**, Jingdi Lei, Haodong Zhao, and Di Zhang. IAG: Input-Aware Backdoor Attack on VLM-Based Visual Grounding. **CVPR 2026**.

**2025**

* Weida Wang, Benteng Chen, Di Zhang, Wanhao Liu, Shuchen Pu, Ben Gao, Jin Zeng, Xiaoyong Wei, Tianshu Yu, Shuzhou Sun, Tianfan Fu, Wanli Ouyang, Lei Bai, **Jiatong Li**, Zifu Wang, Yuqiang Li, Shufei Zhang. Chem-R: Learning to Reason as a Chemist. arXiv preprint arXiv:2510.16880. (Corresponding Author)
* **Jiatong Li**, Weida Wang\*, Qinggang Zhang, Junxian Li, Di Zhang, Changmeng Zheng, Shufei Zhang, Xiaoyong Wei, and Qing Li. Mol-R1: Towards Explicit Long-CoT Reasoning in Molecule Discovery. arXiv preprint arXiv:2508.08401.
* Di Zhang, Jingdi Lei, Junxian Li, Xunzhi Wang, Yujie Liu, Zonglin Yang, **Jiatong Li**, Weida Wang, Suorong Yang, Jianbo Wu, Peng Ye, Wanli Ouyang, Dongzhan Zhou. Critic-V: VLM Critics Help Catch VLM Errors in Multimodal Reasoning. **CVPR 2025**.
* Di Zhang, Jianbo Wu, Jingdi Lei, Tong Che, **Jiatong Li**, Tong Xie, Xiaoshui Huang, Shufei Zhang, Marco Pavone, Yuqiang Li, Wanli Ouyang, Dongzhan Zhou. Llama-Berry: Pairwise Optimization for O1-like Olympiad-Level Mathematical Reasoning. **NAACL 2025**.

**2024**

* **Jiatong Li**\*, Junxian Li\*, Yunqing Liu, Dongzhan Zhou, and Qing Li. TOMG-Bench: Evaluating LLMs on Text-based Open Molecule Generation. arXiv preprint arXiv:2412.14642.
* **Jiatong Li**, Yunqing Liu, Wei Liu, Jingdi Le, Di Zhang, Wenqi Fan, Dongzhan Zhou, Yuqiang Li, and Qing Li. MolReFlect: Towards In-Context Fine-grained Alignments between Molecules and Texts. arXiv preprint arXiv:2411.14721.
* Di Zhang, Wei Liu, Qian Tan, Jingdan Chen, Hang Yan, Yuliang Yan, **Jiatong Li**, Weiran Huang, Xiangyu Yue, Wanli Ouyang, Dongzhan Zhou, Shufei Zhang, Mao Su, Han-Sen Zhong, Yuqiang Li. ChemLLM: A Chemical Large Language Model. arXiv preprint arXiv:2402.06852.
* **Jiatong Li**, Wei Liu, Zhihao Ding, Wenqi Fan, Yuqiang Li, Qing Li. Large Language Models are In-Context Molecule Learners. **IEEE TKDE**.

**2023**

* Lin Wang, Wenqi Fan, **Jiatong Li**, Yao Ma, and Qing Li. Fast Graph Condensation with Structure-based Neural Tangent Kernel. **WWW 2024**.
* Wenqi Fan, Zihuai Zhao, **Jiatong Li**, Yunqing Liu, Xiaowei Mei, Yiqi Wang, Jiliang Tang, and Qing Li. Recommender Systems in the Era of Large Language Models (LLMs). **IEEE TKDE**.
* **Jiatong Li**, Yunqing Liu, Wenqi Fan, Xiao-yong Wei, Hui Liu, Jiliang Tang, Qing Li. Empowering Molecule Discovery for Molecule-Caption Translation with Large Language Models: A ChatGPT Perspective. **IEEE TKDE**.
* Lea Frermann, **Jiatong Li**, Shima Khanehzar, Gosia Mikolajczak. Conflicts, Villains, Resolutions: Towards Models of Narrative Media Framing. **ACL 2023**. (Oral Presentation)
* Wenqi Fan, Chengyi Liu, Yunqing Liu, **Jiatong Li**, Hang Li, Hui Liu, Jiliang Tang, Qing Li. Generative Diffusion Models on Graphs: Methods and Applications. **IJCAI 2023**.

**2022**

* Mao Qinghua, **Jiatong Li**, and Kui Meng. Improving Chinese Named Entity Recognition by Search Engine Augmentation. arXiv preprint arXiv:2210.12662.
* **Jiatong Li**, Bin He, and Fei Mi. Exploring Effective Information Utilization in Multi-Turn Topic-Driven Conversations. arXiv preprint arXiv:2209.00250.

**2021**

* **Jiatong Li**, Kui Meng. MFE-NER: Multi-feature Fusion Embedding for Chinese Named Entity Recognition. arXiv preprint arXiv:2109.07877.
* Chaowang Zhao, Jian Yang\*, **Jiatong Li**. Generation of Hospital Emergency Department Layouts Based on Generative Adversarial Networks. Journal of Building Engineering, 43, 102539.
* Chaowang Zhao, Jian Yang\*, Wuyue Xiong, **Jiatong Li**. Two Generative Design Methods of Hospital Operating Department Layouts Based on Healthcare Systematic Layout Planning and Generative Adversarial Network. Journal of Shanghai Jiaotong University (Science), 26, 103-115.

</div>

Scholarship
------
* Hong Kong PhD Fellowship Scheme (HKPFS)
* Melbourne Graduate Grant

Awards
------
* Second Prize, Aecore Cup Digital Twin Application Competition, 2021
* Finalist Award, Mathematical Contest in Modelling (MCM), 2020

Hobbies
------
<iframe allow="autoplay *; encrypted-media *; fullscreen *; clipboard-write" frameborder="0" height="175" style="width:100%;max-width:660px;overflow:hidden;border-radius:10px;" sandbox="allow-forms allow-popups allow-same-origin allow-scripts allow-storage-access-by-user-activation allow-top-navigation-by-user-activation" src="https://embed.music.apple.com/cn/song/%E5%A4%A9%E7%A9%BA%E6%B2%A1%E6%9C%89%E6%9E%81%E9%99%90-%E7%B2%A4/1818540482"></iframe>

Contact
------
Welcome to contact me via email: jiatong.li AT connect.polyu.hk
